{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Web Scraping For Beginners with Python](https://medium.com/@durgaswaroop/web-scraping-with-python-introduction-7b3c0bbb6053)\n",
    "* [Web Scraping in Python](https://medium.com/dreidev/web-scraping-in-python-e07fba0a1663)\n",
    "* [Web Scraping](https://medium.com/tag/web-scraping)\n",
    "* [Web Scraping Tutorial with Python: Tips and Tricks](https://hackernoon.com/web-scraping-tutorial-with-python-tips-and-tricks-db070e70e071)\n",
    "* [SQLite Python tutorial](http://zetcode.com/db/sqlitepythontutorial/)\n",
    "* [Better web scraping in Python with Selenium, Beautiful Soup, and pandas](https://medium.freecodecamp.org/better-web-scraping-in-python-with-selenium-beautiful-soup-and-pandas-d6390592e251)\n",
    "* [Locating Elements within Selenium](https://selenium-python.readthedocs.io/locating-elements.html#locating-by-id)\n",
    "* [Beautiful Soup Documentation](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find)\n",
    "* [1MDB](https://en.wikipedia.org/wiki/1Malaysia_Development_Berhad)\n",
    "* [HOW TO RUN WEB DRIVERS WITH PROXIES IN PYTHON](https://johnpatrickroach.com/2017/03/31/how-to-run-web-drivers-with-proxies-in-python/)\n",
    "* [Automatic news scraping with Python, Newspaper and Feedparser\n",
    "](https://holwech.github.io/blog/Automatic-news-scraper/)\n",
    "* [Web Scraping in Python using Scrapy (with multiple examples)](https://www.analyticsvidhya.com/blog/2017/07/web-scraping-in-python-using-scrapy/)\n",
    "* [Scraping a JS-Rendered Page](http://stanford.edu/~mgorkove/cgi-bin/rpython_tutorials/Scraping_a_Webpage_Rendered_by_Javascript_Using_Python.php)\n",
    "* [How to Scrape Javascript Rendered Websites with Python & Selenium](https://medium.com/@hoppy/how-to-test-or-scrape-javascript-rendered-websites-with-python-selenium-a-beginner-step-by-c137892216aa)\n",
    "* [5 Simple Tips for Efficient Web Crawling using Selenium Python](https://medium.com/dreamcatcher-its-blog/5-simple-tips-for-improving-automated-web-testing-or-efficient-web-crawling-using-selenium-python-43038d7b7916)\n",
    "* [Scraping the full content from a lazy-loading webpage](https://codereview.stackexchange.com/questions/167327/scraping-the-full-content-from-a-lazy-loading-webpage)\n",
    "* [Headless Chrome in AWS](https://robertorocha.info/setting-up-a-selenium-web-scraper-on-aws-lambda-with-python/)\n",
    "* [How To Make Your Selenium Scripts Faster](https://www.linkedin.com/pulse/how-make-your-selenium-tests-faster-alex-siminiuc/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selenium\n",
    "\n",
    "While Selenium might seem tempting and useful, it has one main problem that can't be fixed: performance. By calculating every single thing a browser does, you will need a lot more power. Even PhantomJS does not compete with a simple request. I recommend that you will only use Selenium when you really need to click buttons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "\n",
    "#launch url\n",
    "url = 'http://kanview.ks.gov/PayRates/PayRates_Agency.aspx'\n",
    "\n",
    "chrome_path = os.getcwd() + '/chromedriver'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a new Chrome session\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "driver = webdriver.Chrome(chrome_path,\n",
    "                          chrome_options=chrome_options)\n",
    "driver.implicitly_wait(30)\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the inner html as string\n",
    "#innerHTML = driver.execute_script(\"return document.body.innerHTML\") #returns the inner HTML as a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#After opening the url above, Selenium clicks the specific agency link\n",
    "python_button = driver.find_element_by_id('MainContent_uxLevel1_Agencies_uxAgencyBtn_33') #FHSU\n",
    "\n",
    "python_button.click() #click fhsu link\n",
    "\n",
    "#Selenium hands the page source to Beautiful Soup\n",
    "soup_level1=BeautifulSoup(driver.page_source, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---------------------+--------------------------------+----------------+-------------------+\n",
      "|    | Employee Name       | Job Title                      | Overtime Pay   | Total Gross Pay   |\n",
      "|----+---------------------+--------------------------------+----------------+-------------------|\n",
      "|  0 | Brown,Michelle N    | Acad Adv Career Explr Asst Dir | $0.00          | $44,011.11        |\n",
      "|  1 | Griffin,Patricia L  | Academic Adv Career Explor Dir | $0.00          | $78,350.21        |\n",
      "|  2 | Armstrong,Micki A   | Academic Advisor               | $0.00          | $45,587.69        |\n",
      "|  3 | Fisher,Erica A      | Academic Advisor               | $0.00          | $38,099.14        |\n",
      "|  4 | Fitzhugh,Nanette J  | Academic Advisor               | $0.00          | $47,923.12        |\n",
      "|  5 | Hepner,Kristine R   | Academic Advisor               | $0.00          | $33,616.20        |\n",
      "|  6 | Johnson,Stephanie A | Academic Advisor               | $0.00          | $35,144.78        |\n",
      "|  7 | Leiker,Dawne P      | Academic Advisor               | $0.00          | $34,989.22        |\n",
      "|  8 | Perryman,Janelle L  | Academic Advisor               | $0.00          | $40,374.76        |\n",
      "|  9 | Prickett,Stacy K    | Academic Advisor               | $0.00          | $38,278.96        |\n",
      "| 10 | Terry,Troy A        | Academic Advisor               | $0.00          | $39,843.72        |\n",
      "| 11 | Beckman,Andi S      | Academic Program Specialist    | $0.00          | $33,702.40        |\n",
      "| 12 | Dechant,Joyce D.    | Academic Program Specialist    | $0.00          | $34,912.00        |\n",
      "| 13 | Ostrom,Lesley A     | Academic Program Specialist    | $0.00          | $33,702.40        |\n",
      "| 14 | Spangler,Sherry L   | Academic Program Specialist    | $0.00          | $33,702.40        |\n",
      "+----+---------------------+--------------------------------+----------------+-------------------+\n"
     ]
    }
   ],
   "source": [
    "datalist = [] #empty list\n",
    "x = 0 #counter\n",
    "\n",
    "#Beautiful Soup finds all Job Title links on the agency page and the loop begins\n",
    "for link in soup_level1.find_all('a', \n",
    "                                 id=re.compile(\"^MainContent_uxLevel2_JobTitles_uxJobTitleBtn_\")):\n",
    "    \n",
    "    #Selenium visits each Job Title page\n",
    "    python_button = driver.find_element_by_id('MainContent_uxLevel2_JobTitles_uxJobTitleBtn_' + str(x))\n",
    "    python_button.click() #click link\n",
    "    \n",
    "    #Selenium hands of the source of the specific job page to Beautiful Soup\n",
    "    soup_level2=BeautifulSoup(driver.page_source, 'lxml')\n",
    "\n",
    "    #Beautiful Soup grabs the HTML table on the page\n",
    "    table = soup_level2.find_all('table')[0]\n",
    "    \n",
    "    #Giving the HTML table to pandas to put in a dataframe object\n",
    "    df = pd.read_html(str(table),header=0)\n",
    "    \n",
    "    #Store the dataframe in a list\n",
    "    datalist.append(df[0])\n",
    "    \n",
    "    #Ask Selenium to click the back button\n",
    "    driver.execute_script(\"window.history.go(-1)\") \n",
    "    \n",
    "    #increment the counter variable before starting the loop over\n",
    "    x += 1\n",
    "    \n",
    "    if x > 3 :\n",
    "        break\n",
    "    \n",
    "    #end loop block\n",
    "    \n",
    "#loop has completed\n",
    "\n",
    "#end the Selenium browser session\n",
    "driver.quit()\n",
    "\n",
    "#combine all pandas dataframes in the list into one big dataframe\n",
    "result = pd.concat([pd.DataFrame(datalist[i]) for i in range(len(datalist))],ignore_index=True)\n",
    "\n",
    "#convert the pandas dataframe to JSON\n",
    "json_records = result.to_json(orient='records')\n",
    "\n",
    "#pretty print to CLI with tabulate\n",
    "#converts to an ascii table\n",
    "print(tabulate(result, \n",
    "               headers=[\"Employee Name\",\"Job Title\",\"Overtime Pay\",\"Total Gross Pay\"],\n",
    "               tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open, write, and close the file\n",
    "f = open(path + \"/fhsu_payroll_data.json\",\"w\") #FHSU\n",
    "f.write(json_records)\n",
    "f.close()\n",
    "# sublime: control + cmd + j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modules & Import files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/anaconda3/lib/python36.zip',\n",
       " '/anaconda3/lib/python3.6',\n",
       " '/anaconda3/lib/python3.6/lib-dynload',\n",
       " '/anaconda3/lib/python3.6/site-packages',\n",
       " '/anaconda3/lib/python3.6/site-packages/aeosa',\n",
       " '/anaconda3/lib/python3.6/site-packages/spynner-2.19-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/autopy-1.0.1-py3.6-macosx-10.7-x86_64.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/pyquery-1.4.0-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/unittest2-1.1.0-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/traceback2-1.4.0-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/argparse-1.4.0-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/linecache2-1.0.0-py3.6.egg',\n",
       " '/anaconda3/lib/python3.6/site-packages/IPython/extensions',\n",
       " '/Users/song/.ipython']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sys will check the default path as above for modules we wanna import\n",
    "* 1.Modules in the wrong path: mymodule in folder 'modules', ModuleNotFoundError\n",
    "* 2.Next let's try to manipulate the directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'mymodule'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-789c0ce43099>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmymodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mymodule'"
     ]
    }
   ],
   "source": [
    "import mymodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mymodule' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b2d3d318330c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmymodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhello\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'mymodule' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CEO': 'C. Douglas McMillon',\n",
      " 'CEO Title': 'President, Chief Executive Officer & Director',\n",
      " 'Employees': '2,300,000',\n",
      " 'HQ Location': 'Bentonville, Ark.',\n",
      " 'Industry': 'General Merchandisers',\n",
      " 'Sector': 'Retailing',\n",
      " 'Website': 'www.stock.walmart.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Darren W. Woods',\n",
      " 'CEO Title': 'Chairman & Chief Executive Officer',\n",
      " 'Employees': '71,200',\n",
      " 'HQ Location': 'Irving, Texas',\n",
      " 'Industry': 'Petroleum Refining',\n",
      " 'Sector': 'Energy',\n",
      " 'Website': 'www.exxonmobil.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Warren E. Buffett',\n",
      " 'CEO Title': 'Chairman, President & Chief Executive Officer',\n",
      " 'Employees': '377,000',\n",
      " 'HQ Location': 'Omaha',\n",
      " 'Industry': 'Insurance: Property and Casualty (Stock)',\n",
      " 'Sector': 'Financials',\n",
      " 'Website': 'www.berkshirehathaway.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Timothy D. Cook',\n",
      " 'CEO Title': 'Chairman & Chief Executive Officer',\n",
      " 'Employees': '123,000',\n",
      " 'HQ Location': 'Cupertino, Calif.',\n",
      " 'Industry': 'Computers, Office Equipment',\n",
      " 'Sector': 'Technology',\n",
      " 'Website': 'www.apple.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'David S. Wichmann',\n",
      " 'CEO Title': 'Chairman & Chief Executive Officer',\n",
      " 'Employees': '260,000',\n",
      " 'HQ Location': 'Minnetonka, Minn.',\n",
      " 'Industry': 'Health Care: Insurance and Managed Care',\n",
      " 'Sector': 'Health Care',\n",
      " 'Website': 'www.unitedhealthgroup.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'John H. Hammergren',\n",
      " 'CEO Title': 'Chairman, President & Chief Executive Officer',\n",
      " 'Employees': '64,500',\n",
      " 'HQ Location': 'San Francisco',\n",
      " 'Industry': 'Wholesalers: Health Care',\n",
      " 'Sector': 'Wholesalers',\n",
      " 'Website': 'www.mckesson.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Larry J. Merlo',\n",
      " 'CEO Title': 'President, Chief Executive Officer & Director',\n",
      " 'Employees': '203,000',\n",
      " 'HQ Location': 'Woonsocket, R.I.',\n",
      " 'Industry': 'Health Care: Pharmacy and Other Services',\n",
      " 'Sector': 'Health Care',\n",
      " 'Website': 'www.cvshealth.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Jeffrey P. Bezos',\n",
      " 'CEO Title': 'Chairman, President & Chief Executive Officer',\n",
      " 'Employees': '566,000',\n",
      " 'HQ Location': 'Seattle',\n",
      " 'Industry': 'Internet Services and Retailing',\n",
      " 'Sector': 'Retailing',\n",
      " 'Website': 'www.amazon.com',\n",
      " 'Years on Fortune 500 List': '17'}\n",
      "------\n",
      "{'CEO': 'Randall L. Stephenson',\n",
      " 'CEO Title': 'Chairman, President & Chief Executive Officer',\n",
      " 'Employees': '254,000',\n",
      " 'HQ Location': 'Dallas',\n",
      " 'Industry': 'Telecommunications',\n",
      " 'Sector': 'Telecommunications',\n",
      " 'Website': 'www.att.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Mary T. Barra',\n",
      " 'CEO Title': 'Chairman & Chief Executive Officer',\n",
      " 'Employees': '180,000',\n",
      " 'HQ Location': 'Detroit',\n",
      " 'Industry': 'Motor Vehicles and Parts',\n",
      " 'Sector': 'Motor Vehicles & Parts',\n",
      " 'Website': 'www.gm.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'James P. Hackett',\n",
      " 'CEO Title': 'President, Chief Executive Officer & Director',\n",
      " 'Employees': '202,000',\n",
      " 'HQ Location': 'Dearborn, Mich.',\n",
      " 'Industry': 'Motor Vehicles and Parts',\n",
      " 'Sector': 'Motor Vehicles & Parts',\n",
      " 'Website': 'www.corporate.ford.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n",
      "{'CEO': 'Steven H. Collis',\n",
      " 'CEO Title': 'Chairman, President & Chief Executive Officer',\n",
      " 'Employees': '19,500',\n",
      " 'HQ Location': 'Chesterbrook, Pa.',\n",
      " 'Industry': 'Wholesalers: Health Care',\n",
      " 'Sector': 'Wholesalers',\n",
      " 'Website': 'www.amerisourcebergen.com',\n",
      " 'Years on Fortune 500 List': '24'}\n",
      "------\n"
     ]
    },
    {
     "ename": "TimeoutException",
     "evalue": "Message: timeout\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.41.578706 (5f725d1b4f0a4acbf5259df887244095596231db),platform=Mac OS X 10.13.6 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTimeoutException\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-4335b8998de6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mcompany_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_company_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcompany_link\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcompany_links\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mcompany_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscraper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_company_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-4335b8998de6>\u001b[0m in \u001b[0;36mget_company_data\u001b[0;34m(self, company_link)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_company_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompany_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;34m\"\"\"Extracts and prints out company specific information.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompany_link\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         return {\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \"\"\"\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    322\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTimeoutException\u001b[0m: Message: timeout\n  (Session info: chrome=68.0.3440.106)\n  (Driver info: chromedriver=2.41.578706 (5f725d1b4f0a4acbf5259df887244095596231db),platform=Mac OS X 10.13.6 x86_64)\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "chrome_path = r'/Users/song/GoogleDrive_SMU/MAS/Alternative Data/WebScrapping/chromedriver'\n",
    "\n",
    "class Fortune500Scraper:\n",
    "    def __init__(self, chrome_path):\n",
    "        self.driver = webdriver.Chrome(chrome_path)\n",
    "        self.wait = WebDriverWait(self.driver, 10)\n",
    "\n",
    "    def get_last_line_number(self):\n",
    "        \"\"\"Get the line number of last company loaded into the list of companies.\"\"\"\n",
    "        return int(self.driver.find_element_by_css_selector(\"ul.company-list > li:last-child > a > span:first-child\").text)\n",
    "\n",
    "    def get_links(self, max_company_count=10):\n",
    "        \"\"\"Extracts and returns company links (maximum number of company links for return is provided).\"\"\"\n",
    "        self.driver.get('http://fortune.com/fortune500/list/')\n",
    "        self.wait.until(EC.visibility_of_element_located((By.CSS_SELECTOR, \"ul.company-list\")))\n",
    "\n",
    "        last_line_number = 0\n",
    "        while last_line_number < max_company_count:\n",
    "            self.driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "            self.wait.until(lambda driver: self.get_last_line_number() != last_line_number)\n",
    "            last_line_number = self.get_last_line_number()\n",
    "\n",
    "        return [company_link.get_attribute(\"href\")\n",
    "                for company_link in self.driver.find_elements_by_css_selector(\"ul.company-list > li > a\")]\n",
    "\n",
    "    def get_company_data(self, company_link):\n",
    "        \"\"\"Extracts and prints out company specific information.\"\"\"\n",
    "        self.driver.get(company_link)\n",
    "\n",
    "        return {\n",
    "            row.find_element_by_css_selector(\".company-info-card-label\").text: row.find_element_by_css_selector(\".company-info-card-data\").text\n",
    "            for row in self.driver.find_elements_by_css_selector('.company-info-card-table > .columns > .row')\n",
    "        }\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    scraper = Fortune500Scraper(chrome_path)\n",
    "\n",
    "    company_links = scraper.get_links(max_company_count=100)\n",
    "    for company_link in company_links:\n",
    "        company_data = scraper.get_company_data(company_link)\n",
    "        pprint(company_data)\n",
    "        print(\"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
